{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from scipy.stats import pearsonr\n",
    "import ssl\n",
    "# следующая строчка подключает сертификат для защищенного соединения\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='http://yustiks.ru/dataset/SPAM_text.csv'\n",
    "data=pd.read_csv(url) \n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[2, 'Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Создадим новый атрибут Category, где будем указывать,\n",
    "# что если данный текст является СПАМом, то 1, если не является, то 0\n",
    "data[\"Category\"] = [1 if each == \"spam\" else 0 for each in data[\"Category\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "# Создаем слова. На основе слов пишем для каждого текста словарь,\n",
    "# где каждое слово - это ключ, а значение ключа - это сколько раз встречается данное слова в данном тексте.\n",
    "\n",
    "# Как пример: рассмотрим 1 строку из датасета.\n",
    "\n",
    "# Удалим все символы, не являющимися латинскими буквами\n",
    "# Заглавные буквы меняем на строчные\n",
    "# Разделим текст на слова\n",
    "# В каждом слове выделяем корень слова\n",
    "# Создаем список всех слов\n",
    "import re\n",
    "nlp_data = str(data.loc[2, 'Message'])\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = re.sub(\"[^a-zA-Z]\",\" \", nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free entry in   a wkly comp to win fa cup final tkts   st may       text fa to       to receive entry question std txt rate t c s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = nlp_data.lower()\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Leo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk as nlp\n",
    "nlp.download('punkt')\n",
    "nlp_data = nlp.word_tokenize(nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Leo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    }
   ],
   "source": [
    "nlp.download('wordnet')\n",
    "lemma = nlp.WordNetLemmatizer()\n",
    "nlp_data = [lemma.lemmatize(word) for word in nlp_data]\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_data = \" \".join(nlp_data)\n",
    "description_list = []\n",
    "for description in data[\"Message\"]:\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower()\n",
    "    description = nlp.word_tokenize(description)\n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description]\n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сколько всего получилось слов в словаре мешка слов\n",
    "len(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые часто встречаемые 3000 слов: ['aah', 'aathi', 'abi', 'ability', 'abiola', 'able', 'absolutly', 'abt', 'abta', 'ac', 'academic', 'acc', 'accept', 'access', 'accident', 'accidentally', 'accordingly', 'account', 'ache', 'aco', 'action', 'activate', 'active', 'activity', 'actor', 'actual', 'actually', 'ad', 'add', 'addamsfa', 'added', 'addicted', 'addie', 'address', 'admin', 'admirer', 'adore', 'adoring', 'adult', 'advance', 'adventure', 'advice', 'advise', 'ae', 'affair', 'affection', 'afraid', 'aft', 'afternoon', 'aftr', 'agalla', 'age', 'ago', 'ah', 'aha', 'ahead', 'ahmad', 'aid', 'aight', 'ain', 'aint', 'air', 'airport', 'airtel', 'aiya', 'aiyah', 'aiyar', 'aiyo', 'aj', 'aka', 'al', 'alaipayuthe', 'album', 'alcohol', 'alert', 'alex', 'alfie', 'algarve', 'ali', 'alive', 'allah', 'allow', 'alright', 'alrite', 'alwys', 'amazing', 'american', 'amp', 'amt', 'amused', 'andros', 'angry', 'animation', 'annie', 'anniversary', 'announcement', 'anot', 'ansr', 'answer', 'answering', 'anti', 'anybody', 'anymore', 'anythin', 'anytime', 'anyways', 'aom', 'apartment', 'apo', 'apologise', 'app', 'apparently', 'apple', 'application', 'apply', 'appointment', 'appreciate', 'apps', 'appt', 'april', 'ar', 'arcade', 'ard', 'area', 'aren', 'argh', 'argue', 'argument', 'arm', 'armand', 'arng', 'arrange', 'arrested', 'arrive', 'arsenal', 'art', 'arun', 'asap', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'asp', 'assume', 'ate', 'atlanta', 'atlast', 'atm', 'attempt', 'attend', 'auction', 'audition', 'audrey', 'august', 'aunt', 'aunty', 'auto', 'available', 'avatar', 'ave', 'avent', 'avoid', 'avoiding', 'await', 'awaiting', 'awake', 'award', 'awarded', 'away', 'awesome', 'aww', 'ayn', 'ba', 'babe', 'baby', 'bad', 'bag', 'bahamas', 'bak', 'balance', 'ball', 'bank', 'bar', 'barely', 'base', 'basic', 'basically', 'bat', 'batch', 'bath', 'bathe', 'bathing', 'battery', 'bay', 'bb', 'bbd', 'bck', 'bcm', 'bcoz', 'bcums', 'bday', 'bear', 'beautiful', 'beauty', 'bec', 'becoz', 'bed', 'bedrm', 'bedroom', 'beer', 'befor', 'beg', 'begin', 'behave', 'bein', 'believe', 'belive', 'bell', 'belly', 'belovd', 'beloved', 'ben', 'beneath', 'best', 'bet', 'better', 'beware', 'bf', 'bid', 'big', 'bigger', 'biggest', 'billed', 'billion', 'bin', 'bird', 'birla', 'birth', 'birthdate', 'birthday', 'bishan', 'bit', 'bitch', 'bite', 'biz', 'bk', 'black', 'blackberry', 'blah', 'blake', 'blame', 'blank', 'bleh', 'bless', 'blessing', 'blind', 'bloke', 'blonde', 'bloo', 'blood', 'bloody', 'bloomberg', 'blow', 'blu', 'blue', 'bluetooth', 'blur', 'bmw', 'boat', 'body', 'bold', 'bone', 'bonus', 'boo', 'book', 'booked', 'booking', 'boost', 'booty', 'bootydelious', 'bored', 'borin', 'boring', 'born', 'borrow', 'bos', 'boston', 'bother', 'bottle', 'bought', 'bout', 'bowl', 'box', 'boy', 'boye', 'boyfriend', 'boytoy', 'brah', 'brain', 'brand', 'bray', 'break', 'breathe', 'brief', 'bright', 'brilliant', 'bring', 'bringing', 'brings', 'bristol', 'british', 'britney', 'bro', 'broad', 'broke', 'bros', 'brothas', 'brother', 'brought', 'bruce', 'bruv', 'bslvyl', 'bstfrnd', 'bt', 'btw', 'buck', 'bud', 'buddy', 'budget', 'buff', 'buffet', 'bugis', 'build', 'building', 'bun', 'burger', 'burn', 'bus', 'business', 'busy', 'butt', 'buy', 'buyer', 'buying', 'buzy', 'buzz', 'bx', 'bye', 'cabin', 'cafe', 'cake', 'cal', 'calculation', 'calicut', 'california', 'callback', 'callcost', 'called', 'caller', 'callertune', 'callfreefone', 'callin', 'calling', 'calm', 'cam', 'camcorder', 'came', 'camera', 'campus', 'canada', 'canal', 'canary', 'cancel', 'cancelled', 'cancer', 'cann', 'captain', 'car', 'card', 'cardiff', 'care', 'cared', 'career', 'careful', 'carefully', 'caring', 'carlos', 'caroline', 'carry', 'cartoon', 'case', 'cash', 'cat', 'catch', 'catching', 'caught', 'cause', 'causing', 'cbe', 'cc', 'cd', 'cdgt', 'celeb', 'celebrate', 'celebration', 'cell', 'center', 'centre', 'certainly', 'cha', 'chain', 'challenge', 'chance', 'change', 'changed', 'channel', 'character', 'charge', 'charged', 'charity', 'chart', 'chasing', 'chat', 'chatting', 'cheap', 'cheaper', 'chechi', 'check', 'checked', 'checking', 'cheer', 'cheese', 'chennai', 'chest', 'chicken', 'chikku', 'child', 'childish', 'chill', 'chillin', 'china', 'chinese', 'chocolate', 'choice', 'choose', 'chosen', 'christmas', 'church', 'cine', 'cinema', 'citizen', 'city', 'claim', 'claire', 'clark', 'class', 'cld', 'clean', 'cleaning', 'clear', 'cleared', 'clearing', 'clever', 'click', 'clock', 'clos', 'close', 'closed', 'closer', 'clothes', 'club', 'cm', 'cn', 'cnn', 'coast', 'coat', 'cock', 'code', 'coffee', 'coin', 'cold', 'colleague', 'collect', 'collected', 'collecting', 'collection', 'college', 'color', 'colour', 'com', 'combine', 'come', 'comedy', 'comfort', 'comin', 'coming', 'commercial', 'common', 'community', 'comp', 'company', 'competition', 'complaint', 'complete', 'completed', 'completely', 'complimentary', 'compromised', 'computer', 'comuk', 'concentrate', 'concert', 'condition', 'conduct', 'confidence', 'confirm', 'confirmd', 'confirmed', 'confuses', 'congrats', 'congratulation', 'connect', 'connection', 'considering', 'console', 'constant', 'constantly', 'contact', 'contacted', 'content', 'continue', 'contract', 'control', 'convey', 'convinced', 'convincing', 'cook', 'cooking', 'cool', 'copy', 'cornwall', 'correct', 'cost', 'costa', 'costing', 'costume', 'couldn', 'count', 'country', 'couple', 'courage', 'course', 'cousin', 'cover', 'coz', 'cr', 'crab', 'crack', 'cramp', 'crap', 'crash', 'crave', 'crazy', 'cream', 'created', 'credit', 'credited', 'crore', 'cross', 'croydon', 'cruise', 'csbcm', 'csh', 'cud', 'cuddle', 'cum', 'cup', 'current', 'currently', 'cust', 'custcare', 'customer', 'cut', 'cute', 'cutefrnd', 'cuz', 'cw', 'da', 'dad', 'daddy', 'dai', 'daily', 'damn', 'dan', 'dance', 'dare', 'dark', 'darlin', 'darling', 'darren', 'dat', 'date', 'dating', 'dave', 'day', 'dbuk', 'dead', 'deal', 'dealer', 'dealing', 'dear', 'dearer', 'dearly', 'death', 'december', 'decide', 'decided', 'decimal', 'decision', 'dedicate', 'dedicated', 'deep', 'deepak', 'deeraj', 'def', 'defeat', 'definite', 'definitely', 'degree', 'del', 'delay', 'delete', 'deleted', 'delhi', 'deliver', 'delivered', 'deliveredtomorrow', 'delivery', 'dem', 'den', 'depends', 'derek', 'desert', 'desire', 'desparate', 'desperate', 'despite', 'detroit', 'deus', 'develop', 'devouring', 'dey', 'di', 'dial', 'diamond', 'dick', 'dictionary', 'did', 'didn', 'didnt', 'die', 'died', 'diet', 'diff', 'difference', 'different', 'difficult', 'dificult', 'digital', 'dignity', 'dime', 'din', 'dinner', 'dint', 'dippeditinadew', 'direct', 'directly', 'director', 'dirty', 'dis', 'disclose', 'disconnect', 'discount', 'discus', 'discussed', 'dislike', 'display', 'distance', 'distract', 'disturb', 'disturbing', 'divorce', 'dload', 'dnt', 'dobby', 'doc', 'dock', 'doctor', 'doe', 'doesn', 'doesnt', 'dog', 'dogging', 'doggy', 'doin', 'doing', 'dokey', 'doll', 'dollar', 'don', 'donno', 'dont', 'door', 'dot', 'double', 'doubt', 'dough', 'download', 'downloads', 'dracula', 'draw', 'dream', 'dress', 'dresser', 'drink', 'drinkin', 'drinking', 'drive', 'driver', 'drivin', 'driving', 'drop', 'dropped', 'drpd', 'drug', 'drunk', 'dry', 'dsn', 'dubsack', 'duchess', 'dude', 'dun', 'dunno', 'dvd', 'ear', 'earlier', 'early', 'earn', 'earth', 'easier', 'easter', 'easy', 'eat', 'eaten', 'eatin', 'eating', 'ebay', 'ec', 'edge', 'edward', 'ee', 'eek', 'eerie', 'effect', 'egg', 'eh', 'eighth', 'eire', 'ela', 'election', 'electricity', 'em', 'email', 'embarassed', 'en', 'end', 'ended', 'ending', 'enemy', 'energy', 'eng', 'engin', 'england', 'english', 'enjoy', 'enjoyed', 'enjoyin', 'enter', 'entered', 'entitled', 'entry', 'enuff', 'envelope', 'epsilon', 'er', 'ericsson', 'erm', 'error', 'escape', 'ese', 'especially', 'esplanade', 'essential', 'eta', 'euro', 'eurodisinc', 'europe', 'eve', 'eveb', 'evening', 'event', 'everybody', 'evn', 'evng', 'evrey', 'evry', 'ex', 'exact', 'exactly', 'exam', 'excellent', 'exciting', 'excuse', 'exe', 'executive', 'exeter', 'exhausted', 'exmpel', 'exorcist', 'expect', 'expecting', 'expensive', 'experience', 'expired', 'expires', 'explain', 'explosive', 'express', 'extra', 'eye', 'fa', 'face', 'facebook', 'fact', 'failed', 'fails', 'fair', 'fake', 'fall', 'falling', 'family', 'fan', 'fancy', 'fantastic', 'fantasy', 'far', 'farm', 'fast', 'faster', 'fat', 'father', 'fathima', 'fault', 'fave', 'favor', 'favorite', 'favour', 'favourite', 'fb', 'fear', 'feb', 'february', 'fee', 'feel', 'feelin', 'feeling', 'fell', 'felt', 'female', 'fetch', 'fever', 'fight', 'fighting', 'fightng', 'figure', 'file', 'filled', 'film', 'filthy', 'final', 'finally', 'finance', 'fine', 'finger', 'finish', 'finished', 'finishing', 'fish', 'fit', 'fix', 'fixed', 'fl', 'flag', 'flaked', 'flaky', 'flame', 'flash', 'flat', 'flight', 'flip', 'flirt', 'floor', 'flower', 'flowing', 'fly', 'fml', 'foley', 'follow', 'followed', 'following', 'fone', 'food', 'fool', 'foot', 'football', 'footprint', 'force', 'foreign', 'forever', 'forevr', 'forget', 'forgets', 'forgiven', 'forgot', 'form', 'format', 'forum', 'forward', 'forwarded', 'fr', 'fran', 'fraud', 'freak', 'free', 'freedom', 'freefone', 'freemsg', 'freephone', 'freezing', 'fren', 'frens', 'fri', 'friday', 'friend', 'friendship', 'fringe', 'frm', 'frnd', 'frnds', 'frndship', 'frog', 'fromm', 'frying', 'fuck', 'fucked', 'fuckin', 'fucking', 'fujitsu', 'ful', 'fullonsms', 'fun', 'function', 'funeral', 'funk', 'funky', 'funny', 'furniture', 'future', 'fwd', 'fyi', 'ga', 'gal', 'galileo', 'game', 'gamestar', 'ganesh', 'gang', 'gap', 'garage', 'garbage', 'gardener', 'gary', 'gas', 'gautham', 'gave', 'gay', 'gb', 'gbp', 'gd', 'ge', 'gee', 'geeee', 'gender', 'generally', 'gent', 'gentle', 'gentleman', 'gently', 'genuine', 'george', 'germany', 'getstop', 'gettin', 'getting', 'getzed', 'geva', 'gf', 'ghost', 'gift', 'gifted', 'gim', 'girl', 'girlfrnd', 'giv', 'given', 'giving', 'glad', 'gm', 'gn', 'goal', 'god', 'goin', 'going', 'gold', 'gon', 'gona', 'gone', 'good', 'goodfriend', 'goodmorning', 'goodnight', 'goodnite', 'goodnoon', 'goodo', 'google', 'gorgeous', 'gossip', 'got', 'goto', 'gotten', 'govt', 'gr', 'grahmbell', 'gram', 'grand', 'grave', 'gravity', 'great', 'greatest', 'green', 'greet', 'greeting', 'grin', 'grl', 'ground', 'group', 'gt', 'guaranteed', 'gud', 'gudnite', 'guess', 'guessing', 'guide', 'guilty', 'guy', 'gv', 'gving', 'gym', 'ha', 'habit', 'haf', 'haha', 'hahaha', 'hai', 'hair', 'haiz', 'half', 'hallaq', 'halloween', 'ham', 'hamster', 'hand', 'handed', 'handle', 'handset', 'hang', 'hanging', 'happen', 'happend', 'happened', 'happening', 'happens', 'happiness', 'happy', 'hard', 'hardcore', 'harry', 'hasn', 'hate', 'hav', 'haven', 'havent', 'havin', 'having', 'havnt', 'head', 'headache', 'headin', 'heading', 'hear', 'heard', 'heart', 'heater', 'heavy', 'hee', 'height', 'held', 'helen', 'hell', 'hella', 'hello', 'helloooo', 'help', 'hey', 'hg', 'hi', 'hide', 'high', 'hill', 'hint', 'hip', 'history', 'hit', 'hiya', 'hl', 'hlp', 'hm', 'hmm', 'hmmm', 'hmv', 'ho', 'hockey', 'hold', 'holder', 'holding', 'holiday', 'holla', 'hols', 'holy', 'home', 'homeowner', 'hon', 'honey', 'honeybee', 'hook', 'hop', 'hope', 'hopefully', 'hoping', 'hor', 'horny', 'horo', 'horrible', 'hospital', 'hostel', 'hot', 'hotel', 'hour', 'house', 'housewife', 'hows', 'howz', 'hp', 'hppnss', 'hr', 'hrishi', 'hsbc', 'http', 'hubby', 'hug', 'huge', 'huh', 'hun', 'hungry', 'hunny', 'hurry', 'hurt', 'hurting', 'husband', 'hv', 'hw', 'iam', 'ibh', 'ibhltd', 'ibiza', 'ibn', 'ic', 'ice', 'icicibank', 'id', 'idea', 'ideal', 'identifier', 'idew', 'idiot', 'idk', 'ignore', 'ikea', 'il', 'ill', 'illness', 'im', 'image', 'imagine', 'imma', 'immediately', 'imp', 'impatient', 'important', 'impossible', 'improved', 'inch', 'incident', 'include', 'including', 'inclusive', 'incredible', 'increment', 'index', 'india', 'indian', 'indicate', 'infernal', 'info', 'inform', 'information', 'informed', 'ing', 'inning', 'innocent', 'inr', 'insha', 'inside', 'installing', 'instantly', 'instead', 'instituitions', 'instruction', 'insurance', 'intelligent', 'intention', 'interested', 'interesting', 'internet', 'interview', 'intro', 'invader', 'invest', 'invite', 'invited', 'inviting', 'invnted', 'iouri', 'ip', 'ipad', 'ipod', 'iq', 'irritates', 'irritating', 'iscoming', 'ish', 'island', 'isn', 'isnt', 'issue', 'italian', 'item', 'itwhichturnedinto', 'itz', 'ive', 'iz', 'izzit', 'ja', 'jacket', 'jackpot', 'jada', 'james', 'jamster', 'jan', 'jane', 'january', 'japanese', 'jas', 'jason', 'java', 'jay', 'jaya', 'jazz', 'jd', 'jealous', 'jen', 'jenny', 'jerry', 'jess', 'jesus', 'jhl', 'jia', 'jiu', 'jo', 'joanna', 'job', 'jogging', 'john', 'join', 'joined', 'joining', 'joke', 'jokin', 'joking', 'jolt', 'jordan', 'journey', 'joy', 'jsco', 'jst', 'jstfrnd', 'jsut', 'juan', 'juicy', 'july', 'june', 'jus', 'just', 'juz', 'kadeem', 'kaiez', 'kallis', 'kano', 'kappa', 'karaoke', 'kate', 'kavalan', 'kb', 'ke', 'keeping', 'kegger', 'kept', 'kerala', 'keralacircle', 'kettoda', 'key', 'kick', 'kid', 'kidding', 'kidz', 'kill', 'killed', 'killing', 'kind', 'kinda', 'kindly', 'king', 'kiss', 'kl', 'knackered', 'knee', 'knew', 'know', 'knowing', 'knw', 'konw', 'kothi', 'kr', 'kusruthi', 'la', 'lab', 'lac', 'lady', 'lag', 'laid', 'land', 'landline', 'langport', 'laptop', 'lar', 'largest', 'late', 'later', 'latest', 'latr', 'laugh', 'laughed', 'laughing', 'laundry', 'law', 'lay', 'lazy', 'lccltd', 'ldew', 'ldn', 'ldnw', 'le', 'lead', 'leaf', 'learn', 'leave', 'leaving', 'lect', 'lecture', 'left', 'leg', 'legal', 'leh', 'lei', 'lem', 'length', 'leona', 'lesson', 'let', 'letter', 'lf', 'liao', 'lib', 'library', 'lick', 'lido', 'lie', 'life', 'lifetime', 'lifpartnr', 'lift', 'light', 'lik', 'like', 'liked', 'likely', 'lil', 'line', 'linerental', 'link', 'lion', 'lionm', 'lionp', 'lip', 'list', 'listen', 'listening', 'literally', 'little', 'live', 'liverpool', 'living', 'lk', 'll', 'lmao', 'lo', 'load', 'loan', 'local', 'location', 'lock', 'log', 'login', 'logo', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'lookatme', 'looked', 'lookin', 'looking', 'lor', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'lotr', 'lou', 'loud', 'lounge', 'lousy', 'lov', 'lovable', 'love', 'loved', 'lovely', 'lover', 'loverboy', 'loving', 'lovingly', 'low', 'loyal', 'loyalty', 'lp', 'lst', 'lt', 'luck', 'lucky', 'lucozade', 'lucy', 'lunch', 'lush', 'luv', 'luxury', 'lv', 'lvblefrnd', 'lyf', 'lyfu', 'lyk', 'ma', 'maangalyam', 'mac', 'machan', 'macho', 'mad', 'madam', 'mag', 'maga', 'magical', 'mah', 'maid', 'mail', 'mailbox', 'main', 'maintain', 'major', 'make', 'making', 'malaria', 'male', 'mall', 'man', 'manage', 'management', 'manda', 'mandan', 'maneesha', 'map', 'march', 'margaret', 'mark', 'market', 'marriage', 'married', 'marry', 'massive', 'master', 'match', 'mate', 'math', 'matrix', 'matter', 'matured', 'maturity', 'max', 'maximize', 'mayb', 'maybe', 'mca', 'mcat', 'meal', 'mean', 'meaning', 'meant', 'measure', 'med', 'medical', 'medicine', 'meet', 'meetin', 'meeting', 'mega', 'meh', 'mel', 'melle', 'melt', 'member', 'membership', 'memory', 'men', 'menu', 'meow', 'merry', 'mesages', 'message', 'messaged', 'messaging', 'messenger', 'messy', 'met', 'mi', 'mid', 'middle', 'midnight', 'mids', 'mila', 'mile', 'milk', 'million', 'min', 'mind', 'mini', 'minimum', 'minmobsmorelkpobox', 'minmoremobsemspobox', 'minnaminunginte', 'minute', 'minuts', 'miracle', 'misbehaved', 'miss', 'missed', 'missin', 'missing', 'mistake', 'mite', 'mitsake', 'mix', 'mk', 'mm', 'mmm', 'mmmm', 'mmmmmm', 'mnth', 'mo', 'moan', 'mob', 'mobile', 'mobilesdirect', 'mobileupd', 'moby', 'mode', 'model', 'module', 'moji', 'mokka', 'mom', 'moment', 'mon', 'monday', 'money', 'monkey', 'mono', 'month', 'monthly', 'mood', 'moon', 'moral', 'morefrmmob', 'morn', 'mornin', 'morning', 'moro', 'morow', 'morphine', 'morro', 'morrow', 'mother', 'motorola', 'mouth', 'moved', 'movie', 'movietrivia', 'moving', 'mp', 'mr', 'mrng', 'mrt', 'mrw', 'msg', 'msging', 'msgrcvd', 'msgrcvdhg', 'msn', 'mt', 'mtalk', 'mth', 'mths', 'mtmsg', 'mtmsgrcvd', 'mu', 'mum', 'mummy', 'mumtaz', 'munsters', 'murder', 'murdered', 'murderer', 'music', 'musthu', 'muz', 'na', 'nah', 'nahi', 'naked', 'nan', 'nap', 'nasdaq', 'nat', 'natalja', 'national', 'natural', 'nature', 'naughty', 'nb', 'nd', 'ne', 'near', 'nearly', 'necessarily', 'neck', 'necklace', 'ned', 'need', 'needed', 'neighbour', 'nervous', 'net', 'netcollex', 'network', 'networking', 'neva', 'new', 'neway', 'newest', 'news', 'ni', 'nice', 'nichols', 'nigeria', 'night', 'nimya', 'nit', 'nite', 'nitros', 'noe', 'nok', 'nokia', 'nokias', 'noline', 'noon', 'nope', 'norm', 'normal', 'normally', 'note', 'nothin', 'notice', 'noun', 'nowadays', 'nt', 'ntt', 'ntwk', 'nu', 'num', 'number', 'nurungu', 'nvm', 'nw', 'nxt', 'ny', 'nyc', 'nydc', 'nyt', 'obviously', 'occupy', 'odi', 'offer', 'office', 'official', 'ofice', 'oh', 'oic', 'ok', 'okay', 'okey', 'okie', 'ola', 'old', 'omg', 'omw', 'oni', 'online', 'onwards', 'oops', 'open', 'opening', 'operator', 'opinion', 'opportunity', 'opt', 'option', 'optout', 'orange', 'orchard', 'order', 'ordered', 'oredi', 'oreo', 'orig', 'original', 'oru', 'oso', 'otside', 'outage', 'outside', 'outstanding', 'outta', 'ow', 'oz', 'pa', 'pack', 'package', 'page', 'paid', 'pain', 'painful', 'painting', 'pale', 'paper', 'paperwork', 'parco', 'parent', 'paris', 'park', 'parked', 'parking', 'partner', 'partnership', 'party', 'pas', 'passed', 'passionate', 'password', 'past', 'path', 'patty', 'pay', 'payed', 'payee', 'paying', 'payment', 'payoh', 'pc', 'peace', 'pending', 'penis', 'penny', 'people', 'percent', 'perfect', 'period', 'person', 'personal', 'personality', 'perwksub', 'pete', 'petrol', 'pg', 'ph', 'philosophy', 'phne', 'phoenix', 'phone', 'phoned', 'photo', 'php', 'pic', 'pick', 'picked', 'picking', 'pickle', 'picsfree', 'picture', 'pie', 'piece', 'pig', 'pilate', 'pimple', 'pin', 'pink', 'piss', 'pissed', 'pix', 'pizza', 'place', 'placement', 'plan', 'plane', 'planned', 'planning', 'play', 'played', 'player', 'playing', 'plaza', 'pleased', 'pleasure', 'plenty', 'pls', 'plus', 'plz', 'pm', 'po', 'pobox', 'pocketbabe', 'pod', 'poem', 'point', 'poker', 'police', 'polo', 'poly', 'polyh', 'polyph', 'polyphonic', 'polys', 'pongal', 'pool', 'poor', 'pop', 'popped', 'porn', 'position', 'possession', 'possible', 'post', 'postcode', 'posted', 'potato', 'potential', 'potter', 'pouch', 'pound', 'pours', 'pout', 'power', 'pp', 'ppermesssubscription', 'ppl', 'pple', 'ppm', 'ppmx', 'ppw', 'prabha', 'practical', 'practice', 'practicing', 'pray', 'praying', 'pre', 'prefer', 'preferably', 'prem', 'premium', 'prepaid', 'prepare', 'prepayment', 'prescription', 'present', 'press', 'pretty', 'previous', 'previously', 'prey', 'price', 'pride', 'prince', 'princess', 'print', 'printed', 'privacy', 'private', 'prize', 'pro', 'prob', 'probably', 'problem', 'probs', 'process', 'processed', 'prof', 'profile', 'profit', 'program', 'project', 'prolly', 'promise', 'prompt', 'proof', 'properly', 'propose', 'propsd', 'prospect', 'protect', 'prove', 'proverb', 'provided', 'pt', 'ptbo', 'pub', 'public', 'pull', 'purchase', 'purity', 'purpose', 'purse', 'push', 'pussy', 'puttin', 'putting', 'qatar', 'qp', 'qu', 'quality', 'queen', 'question', 'questioned', 'quick', 'quickly', 'quit', 'quite', 'quiz', 'quote', 'quoting', 'qxj', 'racing', 'radio', 'raed', 'rael', 'railway', 'rain', 'raining', 'raise', 'raj', 'raji', 'rakhesh', 'rally', 'ran', 'random', 'randomly', 'randy', 'rang', 'range', 'ranjith', 'rate', 'ray', 'rcv', 'rcvd', 'rd', 'reach', 'reached', 'reaching', 'read', 'reader', 'reading', 'ready', 'real', 'reality', 'realize', 'realized', 'really', 'realy', 'reason', 'reasonable', 'reboot', 'recd', 'receipt', 'receive', 'receivea', 'received', 'receiving', 'recent', 'recently', 'recharge', 'reckon', 'record', 'recovery', 'red', 'redeemed', 'ref', 'reference', 'refilled', 'refused', 'regard', 'regarding', 'register', 'registered', 'regret', 'regular', 'relation', 'relax', 'released', 'rem', 'remain', 'remains', 'remember', 'remembered', 'remembr', 'remind', 'reminder', 'removal', 'remove', 'renewal', 'rent', 'rental', 'rentl', 'repair', 'repeat', 'replacement', 'replied', 'reply', 'replying', 'report', 'representative', 'request', 'research', 'reserve', 'respect', 'respectful', 'responce', 'respond', 'responding', 'response', 'responsibility', 'rest', 'restaurant', 'result', 'retrieve', 'return', 'returned', 'reveal', 'revealed', 'review', 'revision', 'reward', 'rewarding', 'rg', 'rhythm', 'rice', 'rich', 'ride', 'right', 'ring', 'ringtone', 'ringtoneking', 'ringtones', 'rite', 'river', 'road', 'roast', 'rock', 'rofl', 'roger', 'role', 'romantic', 'ron', 'room', 'roommate', 'rose', 'round', 'row', 'royal', 'rply', 'rr', 'ru', 'rub', 'rude', 'ruin', 'rule', 'rumour', 'run', 'running', 'rush', 'rw', 'ryan', 'sachin', 'sacrifice', 'sad', 'sae', 'safe', 'said', 'sake', 'salary', 'sale', 'salon', 'sam', 'santa', 'sarcasm', 'sarcastic', 'sat', 'sathya', 'satisfied', 'satisfy', 'saturday', 'saucy', 'savamob', 'save', 'saved', 'saw', 'say', 'saying', 'scared', 'scary', 'sch', 'schedule', 'school', 'science', 'scold', 'score', 'scoring', 'scotland', 'scream', 'screaming', 'screen', 'se', 'sea', 'search', 'searching', 'season', 'seat', 'sec', 'second', 'secret', 'secretary', 'section', 'sed', 'seeing', 'seen', 'selected', 'selection', 'self', 'sell', 'selling', 'sem', 'semester', 'sen', 'send', 'sender', 'sending', 'sense', 'sensitive', 'sent', 'sentence', 'senthil', 'sept', 'series', 'seriously', 'service', 'set', 'setting', 'settle', 'settled', 'seven', 'sex', 'sexy', 'sh', 'sha', 'shagged', 'shahjahan', 'shall', 'shame', 'share', 'shd', 'sheet', 'shelf', 'shesil', 'shijas', 'shining', 'ship', 'shipping', 'shirt', 'shit', 'shitload', 'shld', 'shocking', 'shoot', 'shop', 'shopping', 'shore', 'short', 'shortage', 'shorter', 'shortly', 'shot', 'shouldn', 'shouted', 'shower', 'showing', 'shracomorsglsuplt', 'shu', 'shuhui', 'shut', 'shy', 'si', 'sian', 'sib', 'sick', 'sigh', 'sight', 'sign', 'signing', 'silence', 'silent', 'silver', 'sim', 'simple', 'simpler', 'simply', 'sinco', 'sing', 'single', 'sipix', 'sir', 'sister', 'sit', 'site', 'sitll', 'sitting', 'situation', 'size', 'sk', 'skilgme', 'skillgame', 'skip', 'sky', 'skype', 'slap', 'slave', 'sleep', 'sleeping', 'sleepwell', 'sleepy', 'slept', 'slice', 'slide', 'slip', 'slipper', 'slot', 'slow', 'slowly', 'sm', 'small', 'smart', 'smashed', 'smeone', 'smile', 'smiling', 'smoke', 'smoking', 'smth', 'sn', 'snake', 'snow', 'snowman', 'social', 'sofa', 'soft', 'software', 'sol', 'solve', 'solved', 'somebody', 'somethin', 'somtimes', 'song', 'sony', 'sonyericsson', 'soon', 'sooner', 'sooooo', 'sore', 'sorrow', 'sorry', 'sort', 'sorted', 'sorting', 'sory', 'soryda', 'soul', 'sound', 'soup', 'source', 'south', 'sp', 'space', 'spanish', 'spare', 'speak', 'special', 'specially', 'specific', 'speechless', 'speed', 'spell', 'spend', 'spending', 'spent', 'spider', 'spile', 'spk', 'spl', 'splleing', 'spoiled', 'spoke', 'spoken', 'spook', 'sport', 'spree', 'spring', 'sptv', 'sry', 'st', 'staff', 'stamp', 'stamped', 'stand', 'standard', 'standing', 'star', 'staring', 'start', 'started', 'starting', 'starwars', 'statement', 'station', 'status', 'stay', 'stayed', 'stayin', 'staying', 'std', 'step', 'steve', 'stick', 'sticky', 'stock', 'stockport', 'stomach', 'stomp', 'stone', 'stop', 'stopped', 'stoptxt', 'store', 'storming', 'story', 'str', 'straight', 'stranger', 'street', 'stress', 'stretch', 'strike', 'strong', 'stuck', 'student', 'study', 'studying', 'stuff', 'stupid', 'style', 'stylish', 'sub', 'subpoly', 'subscribe', 'subscribed', 'subscriber', 'subscription', 'successful', 'successfully', 'suck', 'sucker', 'sue', 'sugar', 'suggest', 'suggestion', 'suite', 'sum', 'summer', 'sumthin', 'sun', 'sunday', 'sunlight', 'sunny', 'sunshine', 'suntec', 'sup', 'super', 'supervisor', 'supply', 'support', 'suppose', 'supposed', 'suprman', 'sura', 'sure', 'surely', 'surfing', 'surprise', 'surprised', 'sux', 'suzy', 'sw', 'swatch', 'sweet', 'sweetest', 'sweetie', 'swimming', 'swing', 'swiss', 'switch', 'swoop', 'swt', 'swtheart', 'symbol', 'ta', 'table', 'tablet', 'taco', 'tahan', 'taken', 'takin', 'taking', 'talent', 'talk', 'talking', 'tampa', 'tap', 'tape', 'tariff', 'tat', 'taunton', 'taxi', 'taylor', 'tayseer', 'tb', 'tc', 'tcr', 'tea', 'teach', 'teacher', 'teaching', 'team', 'tear', 'tease', 'teasing', 'tech', 'technical', 'tee', 'teeth', 'tel', 'telephone', 'tell', 'telling', 'telly', 'telphone', 'telugu', 'temp', 'temple', 'tenant', 'tenerife', 'term', 'terrible', 'terrorist', 'tessy', 'test', 'testing', 'text', 'textcomp', 'texted', 'texting', 'textoperator', 'textpod', 'tf', 'th', 'thangam', 'thank', 'thanks', 'thanksgiving', 'thanx', 'thats', 'theatre', 'themob', 'theory', 'thgt', 'thing', 'think', 'thinkin', 'thinking', 'thk', 'thm', 'thnk', 'tho', 'thought', 'thread', 'threat', 'throat', 'throw', 'tht', 'thts', 'thurs', 'thursday', 'ti', 'tick', 'ticket', 'tight', 'tihs', 'til', 'till', 'time', 'timing', 'tip', 'tired', 'tirunelvali', 'tirupur', 'tissco', 'title', 'tkts', 'tlk', 'tlp', 'tm', 'tmr', 'tmrw', 'tnc', 'tncs', 'toa', 'toclaim', 'today', 'tog', 'tok', 'told', 'toll', 'tom', 'tomarrow', 'tomeandsaid', 'tomo', 'tomorrow', 'ton', 'tone', 'tonight', 'tonite', 'took', 'tool', 'tooo', 'tooth', 'topic', 'torch', 'tortilla', 'tot', 'total', 'totally', 'touch', 'touched', 'tough', 'toughest', 'tour', 'town', 'tr', 'track', 'trade', 'traffic', 'train', 'training', 'transaction', 'transfer', 'transfered', 'transfr', 'transport', 'trav', 'travel', 'treat', 'tree', 'tried', 'trip', 'trouble', 'true', 'truly', 'trust', 'truth', 'try', 'trying', 'tsandcs', 'tscs', 'tsunami', 'tt', 'ttyl', 'tues', 'tuesday', 'tuition', 'turn', 'turning', 'tv', 'twice', 'twilight', 'txt', 'txtauction', 'txtin', 'txting', 'txts', 'txtstop', 'tyler', 'type', 'tyrone', 'ubi', 'ugh', 'uh', 'uk', 'umma', 'ummmmmaah', 'unable', 'uncle', 'understand', 'understanding', 'understood', 'underwear', 'unemployed', 'unfortunately', 'uni', 'unique', 'university', 'unknown', 'unless', 'unlimited', 'unnecessarily', 'unredeemed', 'unsold', 'unsub', 'unsubscribe', 'upd', 'update', 'upgrade', 'upload', 'upset', 'upstairs', 'upto', 'ur', 'urawinner', 'ure', 'urgent', 'urgently', 'urgnt', 'url', 'urn', 'urself', 'usc', 'use', 'used', 'user', 'usf', 'usher', 'using', 'usual', 'usually', 'utter', 'uz', 'valentine', 'valid', 'valuable', 'value', 'valued', 'various', 'vary', 'vava', 'vday', 've', 'vega', 'vegetable', 'verified', 'verify', 'version', 'vettam', 'vewy', 'vid', 'video', 'videochat', 'videophones', 'vijay', 'vikky', 'village', 'violated', 'violence', 'vip', 'virgin', 'visionsms', 'visit', 'vivek', 'vl', 'voda', 'vodafone', 'vodka', 'voice', 'voicemail', 'vomit', 'vomiting', 'vote', 'voucher', 'vry', 'vth', 'vu', 'wa', 'wah', 'waheed', 'waht', 'wait', 'waited', 'waitin', 'waiting', 'wake', 'waking', 'wale', 'walk', 'walked', 'walking', 'wall', 'wallpaper', 'walmart', 'wan', 'wana', 'want', 'wanted', 'wanting', 'wap', 'warm', 'warner', 'wasn', 'waste', 'wat', 'watch', 'watching', 'water', 'wating', 'wats', 'wave', 'waxsto', 'way', 'wb', 'wc', 'weak', 'weakness', 'wear', 'wearing', 'weather', 'web', 'website', 'wed', 'wedding', 'wednesday', 'weed', 'week', 'weekend', 'weekly', 'weigh', 'weight', 'weird', 'weirdest', 'welcome', 'welp', 'wen', 'went', 'wer', 'wet', 'whats', 'whenevr', 'white', 'whn', 'wicklow', 'wid', 'widelive', 'wif', 'wife', 'wifi', 'wihtuot', 'wil', 'willing', 'win', 'winaweek', 'winawk', 'wind', 'window', 'wine', 'winner', 'winning', 'wipro', 'wisdom', 'wise', 'wish', 'wishin', 'wishing', 'wit', 'wiv', 'wk', 'wkend', 'wkg', 'wkly', 'wks', 'wml', 'wn', 'wnt', 'wo', 'woke', 'woken', 'woman', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'word', 'work', 'workin', 'working', 'world', 'worried', 'worry', 'worse', 'worth', 'wot', 'wouldn', 'wow', 'wp', 'wq', 'wrc', 'write', 'wrk', 'wrnog', 'wrong', 'wrote', 'wt', 'wtf', 'wu', 'wud', 'wuld', 'wun', 'www', 'wx', 'wylie', 'xam', 'xavier', 'xchat', 'xh', 'xin', 'xmas', 'xuhui', 'xx', 'xxx', 'xxxmobilemovieclub', 'xxxx', 'xxxxx', 'xxxxxxx', 'xxxxxxxxx', 'xy', 'ya', 'yahoo', 'yan', 'yar', 'yay', 'yeah', 'year', 'yeh', 'yellow', 'yep', 'yer', 'yes', 'yest', 'yesterday', 'yetunde', 'yijue', 'ym', 'yo', 'yoga', 'yogasana', 'yor', 'youre', 'yr', 'yummy', 'yun', 'yuo', 'yup', 'zed', 'zindgi']\n"
     ]
    }
   ],
   "source": [
    "#Создаем bag-of-words, для этого выбираем 3000 максимально встречаемых слов\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "max_features = 3000\n",
    "count_vectorizer = CountVectorizer(max_features = max_features, stop_words = \"english\")\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "print(\"Самые часто встречаемые {} слов: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,0].values\n",
    "x = sparce_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делим данные на тренировочные и тестовые\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of our model: 0.8780269058295964\n"
     ]
    }
   ],
   "source": [
    "#наивный байес\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       966\n",
      "           1       0.53      0.89      0.66       149\n",
      "\n",
      "    accuracy                           0.88      1115\n",
      "   macro avg       0.75      0.88      0.79      1115\n",
      "weighted avg       0.92      0.88      0.89      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.9811659192825112\n"
     ]
    }
   ],
   "source": [
    "#логистическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       966\n",
      "           1       1.00      0.86      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.93      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With KNN (K=3) accuracy is:  0.9417040358744395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train,y_train)\n",
    "#print('Prediction: {}'.format(prediction))\n",
    "print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       966\n",
      "           1       1.00      0.56      0.72       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.97      0.78      0.84      1115\n",
      "weighted avg       0.95      0.94      0.93      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Из всех выбранных моделей лучше всего дала результаты модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задача - определить класс, к которому относится тот или иной текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#Удаляем слова, которые не имеют смысловой нагрузки (например, слова 'и', 'или', 'а' и другие)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(line):\n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее функция, с помощью которой мы будем обрабатывать твиты\n",
    "\n",
    "# переводим все слова в строчные буквы\n",
    "# удаляем цифры\n",
    "# удаляем пунктуацию\n",
    "# удаляем стоп-слова\n",
    "def preprocess(line):\n",
    "  # все слова переводим в строчный текст\n",
    "    line = line.lower()\n",
    "  # удаляем цифры\n",
    "    line = re.sub(r'\\d+', '', line)\n",
    "  # удаляем пунктуацию\n",
    "    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))\n",
    "    line = remove_stopwords(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-736ef504d7fa>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.Message[i] = preprocess(line)\n"
     ]
    }
   ],
   "source": [
    "train = data\n",
    "\n",
    "for i,line in enumerate(train.Message):\n",
    "    train.Message[i] = preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>nd time tried contact u u £ pound prize claim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>pity mood soany suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>guy bitching acted like id interested buying s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message\n",
       "0            0  go jurong point crazy available bugis n great ...\n",
       "1            0                            ok lar joking wif u oni\n",
       "2            1  free entry wkly comp win fa cup final tkts st ...\n",
       "3            0                u dun say early hor u c already say\n",
       "4            0        nah dont think goes usf lives around though\n",
       "...        ...                                                ...\n",
       "5567         1  nd time tried contact u u £ pound prize claim ...\n",
       "5568         0                        ü b going esplanade fr home\n",
       "5569         0                        pity mood soany suggestions\n",
       "5570         0  guy bitching acted like id interested buying s...\n",
       "5571         0                                     rofl true name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 747 entries, 2 to 5567\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  747 non-null    int64 \n",
      " 1   Message   747 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 17.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4825 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  4825 non-null   int64 \n",
      " 1   Message   4825 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 113.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Разделим датасет на тренировочный и тестовый\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['Message'], train['Category'], \n",
    "                                                    test_size=0.5, stratify=train['Category'])\n",
    "\n",
    "trainp=train[train.Category==1]\n",
    "trainn=train[train.Category==0]\n",
    "print(trainp.info())\n",
    "trainn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно заметить, что классы несбалансированы: в классе 1 2242 элемента, а в классе 0 их 29720.\n",
    "\n",
    "# Создадим bag-of-words вектора для всех твитов\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer()\n",
    "tf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\n",
    "tf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2413\n",
      "           1       0.92      0.91      0.91       373\n",
      "\n",
      "    accuracy                           0.98      2786\n",
      "   macro avg       0.95      0.95      0.95      2786\n",
      "weighted avg       0.98      0.98      0.98      2786\n",
      "\n",
      "[[2382   31]\n",
      " [  35  338]]\n"
     ]
    }
   ],
   "source": [
    "#наивный байес\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X=tf_train,y=y_train)\n",
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно заметить, что класс 1 предсказывается намного хуже, чем класс 0: класса 1 намного меньше по числу элементов, чем класс 0.\n",
    "\n",
    "# Сбалансируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    4825\n",
      "1     747\n",
      "Name: Category, dtype: int64\n",
      "After\n",
      "1    4825\n",
      "0    4825\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_imbalanced = train\n",
    "from sklearn.utils import resample\n",
    "df_majority = train[train.Category==0]\n",
    "df_minority = train[train.Category==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"Before\")\n",
    "print(train.Category.value_counts())\n",
    "print(\"After\")\n",
    "print(df_upsampled.Category.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_upsampled['Message'], df_upsampled['Category'], test_size=0.5, stratify=df_upsampled['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тренировочных данных стало больше, и классы уравнялись\n",
    "#балансировка привела к улучшению результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      2412\n",
      "           1       0.96      0.97      0.96      2413\n",
      "\n",
      "    accuracy                           0.96      4825\n",
      "   macro avg       0.96      0.96      0.96      4825\n",
      "weighted avg       0.96      0.96      0.96      4825\n",
      "\n",
      "Матрица confusion\n",
      "[[2306  106]\n",
      " [  73 2340]]\n"
     ]
    }
   ],
   "source": [
    "tf_train=vect.transform(X_train)\n",
    "tf_test=vect.transform(X_test)\n",
    "model.fit(X=tf_train,y=y_train)\n",
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('Матрица confusion')\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
